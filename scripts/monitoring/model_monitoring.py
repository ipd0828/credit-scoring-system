"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç:
1. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
2. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
3. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–º–µ—â–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
4. –û—Ç–ø—Ä–∞–≤–∫—É –∞–ª–µ—Ä—Ç–æ–≤ –ø—Ä–∏ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏
"""

import json
import logging
import os
import warnings
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

import joblib

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
import mlflow
import numpy as np
import pandas as pd
from mlflow.tracking import MlflowClient

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤
from scipy import stats
from scipy.stats import chi2_contingency, ks_2samp
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    precision_score,
    recall_score,
    roc_auc_score,
)

warnings.filterwarnings("ignore")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É logs, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
import os
from pathlib import Path

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É logs –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
project_root = Path(__file__).parent.parent.parent
logs_dir = project_root / "logs"
logs_dir.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(logs_dir / "model_monitoring.log"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


class ModelMonitor:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π.
    """

    def __init__(
        self,
        model_path: str,
        reference_data_path: str,
        monitoring_config: Optional[Dict[str, Any]] = None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∞ –º–æ–¥–µ–ª–∏.

        Args:
            model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            reference_data_path: –ü—É—Ç—å –∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–º –¥–∞–Ω–Ω—ã–º
            monitoring_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        """
        self.model_path = model_path
        self.reference_data_path = reference_data_path
        self.config = monitoring_config or self._default_config()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.model = self._load_model()
        self.reference_data = self._load_reference_data()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow
        self.mlflow_client = MlflowClient()

        logger.info(f"–ú–æ–Ω–∏—Ç–æ—Ä –º–æ–¥–µ–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {model_path}")

    def _default_config(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
        return {
            "drift_threshold": 0.1,  # –ü–æ—Ä–æ–≥ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –¥—Ä–∏—Ñ—Ç–∞
            "performance_threshold": 0.05,  # –ü–æ—Ä–æ–≥ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            "bias_threshold": 0.1,  # –ü–æ—Ä–æ–≥ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–º–µ—â–µ–Ω–∏—è
            "min_samples": 100,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            "alert_email": None,  # Email –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤
            "slack_webhook": None,  # Slack webhook –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤
            "monitoring_window": 7,  # –û–∫–Ω–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤ –¥–Ω—è—Ö
        }

    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å."""
        try:
            model = joblib.load(self.model_path)
            logger.info(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.model_path}")
            return model
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise

    def _load_reference_data(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
        try:
            data = pd.read_csv(self.reference_data_path)
            logger.info(f"–†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {data.shape}")
            return data
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise

    def detect_data_drift(
        self, current_data: pd.DataFrame, feature_columns: list
    ) -> Dict[str, Any]:
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –¥—Ä–∏—Ñ—Ç –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–º–∏ –∏ —Ç–µ–∫—É—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏.

        Args:
            current_data: –¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            feature_columns: –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –¥—Ä–∏—Ñ—Ç–∞
        """
        logger.info("–ê–Ω–∞–ª–∏–∑ –¥—Ä–∏—Ñ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö...")

        drift_results = {
            "overall_drift_detected": False,
            "feature_drifts": {},
            "drift_score": 0.0,
            "timestamp": datetime.now().isoformat(),
        }

        try:
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            numeric_features = (
                current_data[feature_columns].select_dtypes(include=[np.number]).columns
            )

            drift_scores = []

            for feature in numeric_features:
                if feature in self.reference_data.columns:
                    # KS —Ç–µ—Å—Ç –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    ref_values = self.reference_data[feature].dropna()
                    curr_values = current_data[feature].dropna()

                    if len(ref_values) > 0 and len(curr_values) > 0:
                        statistic, p_value = ks_2samp(ref_values, curr_values)

                        drift_detected = p_value < self.config["drift_threshold"]
                        drift_scores.append(statistic)

                        drift_results["feature_drifts"][feature] = {
                            "drift_detected": drift_detected,
                            "ks_statistic": statistic,
                            "p_value": p_value,
                            "reference_mean": ref_values.mean(),
                            "current_mean": curr_values.mean(),
                            "reference_std": ref_values.std(),
                            "current_std": curr_values.std(),
                        }

            # –û–±—â–∏–π —Å–∫–æ—Ä –¥—Ä–∏—Ñ—Ç–∞
            if drift_scores:
                drift_results["drift_score"] = np.mean(drift_scores)
                drift_results["overall_drift_detected"] = (
                    drift_results["drift_score"] > self.config["drift_threshold"]
                )

            logger.info(
                f"–î—Ä–∏—Ñ—Ç –¥–∞–Ω–Ω—ã—Ö: {drift_results['overall_drift_detected']}, "
                f"—Å–∫–æ—Ä: {drift_results['drift_score']:.4f}"
            )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥—Ä–∏—Ñ—Ç–∞: {e}")
            drift_results["error"] = str(e)

        return drift_results

    def monitor_model_performance(
        self, X_test: pd.DataFrame, y_test: pd.Series
    ) -> Dict[str, Any]:
        """
        –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏.

        Args:
            X_test: –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            y_test: –¢–µ—Å—Ç–æ–≤–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        logger.info("–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏...")

        performance_results = {
            "current_metrics": {},
            "performance_degraded": False,
            "timestamp": datetime.now().isoformat(),
        }

        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred = self.model.predict(X_test)
            y_proba = (
                self.model.predict_proba(X_test)[:, 1]
                if hasattr(self.model, "predict_proba")
                else None
            )

            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            metrics = {
                "accuracy": accuracy_score(y_test, y_pred),
                "precision": precision_score(y_test, y_pred, zero_division=0),
                "recall": recall_score(y_test, y_pred, zero_division=0),
                "f1_score": f1_score(y_test, y_pred, zero_division=0),
            }

            if y_proba is not None:
                metrics["roc_auc"] = roc_auc_score(y_test, y_proba)

            performance_results["current_metrics"] = metrics

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é (–∑–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline)
            # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å—á–∏—Ç–∞–µ–º –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é –µ—Å–ª–∏ F1-score < 0.7
            if metrics["f1_score"] < 0.7:
                performance_results["performance_degraded"] = True
                logger.warning(
                    f"–î–µ–≥—Ä–∞–¥–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞: F1={metrics['f1_score']:.4f}"
                )

            logger.info(f"–¢–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏: {metrics}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
            performance_results["error"] = str(e)

        return performance_results

    def detect_prediction_bias(
        self, X_test: pd.DataFrame, y_test: pd.Series, sensitive_attributes: list
    ) -> Dict[str, Any]:
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç —Å–º–µ—â–µ–Ω–∏–µ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö –º–æ–¥–µ–ª–∏.

        Args:
            X_test: –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            y_test: –¢–µ—Å—Ç–æ–≤–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            sensitive_attributes: –°–ø–∏—Å–æ–∫ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ —Å–º–µ—â–µ–Ω–∏—è
        """
        logger.info("–ê–Ω–∞–ª–∏–∑ —Å–º–µ—â–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")

        bias_results = {
            "bias_detected": False,
            "attribute_bias": {},
            "timestamp": datetime.now().isoformat(),
        }

        try:
            y_pred = self.model.predict(X_test)

            for attr in sensitive_attributes:
                if attr in X_test.columns:
                    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º –∞—Ç—Ä–∏–±—É—Ç–∞
                    groups = X_test[attr].unique()

                    if len(groups) > 1:
                        group_metrics = {}

                        for group in groups:
                            mask = X_test[attr] == group
                            if mask.sum() > 0:
                                group_y_true = y_test[mask]
                                group_y_pred = y_pred[mask]

                                group_metrics[group] = {
                                    "accuracy": accuracy_score(
                                        group_y_true, group_y_pred
                                    ),
                                    "precision": precision_score(
                                        group_y_true, group_y_pred, zero_division=0
                                    ),
                                    "recall": recall_score(
                                        group_y_true, group_y_pred, zero_division=0
                                    ),
                                    "f1_score": f1_score(
                                        group_y_true, group_y_pred, zero_division=0
                                    ),
                                    "sample_size": mask.sum(),
                                }

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏
                        if len(group_metrics) > 1:
                            accuracies = [
                                metrics["accuracy"]
                                for metrics in group_metrics.values()
                            ]
                            max_diff = max(accuracies) - min(accuracies)

                            bias_results["attribute_bias"][attr] = {
                                "group_metrics": group_metrics,
                                "max_accuracy_difference": max_diff,
                                "bias_detected": max_diff
                                > self.config["bias_threshold"],
                            }

                            if max_diff > self.config["bias_threshold"]:
                                bias_results["bias_detected"] = True
                                logger.warning(
                                    f"–°–º–µ—â–µ–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥–ª—è –∞—Ç—Ä–∏–±—É—Ç–∞ {attr}: "
                                    f"—Ä–∞–∑–Ω–∏—Ü–∞ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ {max_diff:.4f}"
                                )

            logger.info(f"–°–º–µ—â–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {bias_results['bias_detected']}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–º–µ—â–µ–Ω–∏—è: {e}")
            bias_results["error"] = str(e)

        return bias_results

    def generate_monitoring_report(
        self,
        current_data: pd.DataFrame,
        X_test: pd.DataFrame,
        y_test: pd.Series,
        feature_columns: list,
        sensitive_attributes: list = None,
    ) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞.

        Args:
            current_data: –¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            X_test: –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            y_test: –¢–µ—Å—Ç–æ–≤–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            feature_columns: –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            sensitive_attributes: –°–ø–∏—Å–æ–∫ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤

        Returns:
            –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        """
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞...")

        report = {
            "timestamp": datetime.now().isoformat(),
            "model_path": self.model_path,
            "reference_data_path": self.reference_data_path,
            "alerts": [],
        }

        try:
            # –ê–Ω–∞–ª–∏–∑ –¥—Ä–∏—Ñ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
            drift_results = self.detect_data_drift(current_data, feature_columns)
            report["data_drift"] = drift_results

            if drift_results.get("overall_drift_detected", False):
                report["alerts"].append(
                    {
                        "type": "data_drift",
                        "severity": "high",
                        "message": "–û–±–Ω–∞—Ä—É–∂–µ–Ω –¥—Ä–∏—Ñ—Ç –¥–∞–Ω–Ω—ã—Ö",
                        "details": f"–û–±—â–∏–π —Å–∫–æ—Ä –¥—Ä–∏—Ñ—Ç–∞: {drift_results['drift_score']:.4f}",
                    }
                )

            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            performance_results = self.monitor_model_performance(X_test, y_test)
            report["performance"] = performance_results

            if performance_results.get("performance_degraded", False):
                report["alerts"].append(
                    {
                        "type": "performance_degradation",
                        "severity": "high",
                        "message": "–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
                        "details": f"F1-score: {performance_results['current_metrics'].get('f1_score', 'N/A')}",
                    }
                )

            # –ê–Ω–∞–ª–∏–∑ —Å–º–µ—â–µ–Ω–∏—è
            if sensitive_attributes:
                bias_results = self.detect_prediction_bias(
                    X_test, y_test, sensitive_attributes
                )
                report["bias"] = bias_results

                if bias_results.get("bias_detected", False):
                    report["alerts"].append(
                        {
                            "type": "prediction_bias",
                            "severity": "medium",
                            "message": "–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–º–µ—â–µ–Ω–∏–µ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö",
                            "details": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã",
                        }
                    )

            # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
            report["overall_status"] = (
                "healthy" if not report["alerts"] else "issues_detected"
            )

            logger.info(
                f"–û—Ç—á–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {len(report['alerts'])} –∞–ª–µ—Ä—Ç–æ–≤"
            )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            report["error"] = str(e)
            report["overall_status"] = "error"

        return report

    def save_monitoring_report(self, report: Dict[str, Any], output_path: str) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞.

        Args:
            report: –û—Ç—á–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        try:
            output_file = (
                Path(output_path)
                / f"monitoring_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )
            output_file.parent.mkdir(parents=True, exist_ok=True)

            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)

            logger.info(f"–û—Ç—á–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")

    def send_alerts(self, report: Dict[str, Any]) -> None:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞–ª–µ—Ä—Ç—ã –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º.

        Args:
            report: –û—Ç—á–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        """
        if not report.get("alerts"):
            return

        logger.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ {len(report['alerts'])} –∞–ª–µ—Ä—Ç–æ–≤...")

        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É email, Slack —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –∏ —Ç.–¥.
        for alert in report["alerts"]:
            logger.warning(
                f"ALERT [{alert['severity'].upper()}]: {alert['message']} - {alert['details']}"
            )


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (–≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ)
    model_path = "models/trained/best_model.pkl"
    reference_data_path = "data/processed/X_train.csv"
    current_data_path = "data/processed/X_test.csv"
    test_labels_path = "data/processed/y_test.csv"

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
    required_files = [
        model_path,
        reference_data_path,
        current_data_path,
        test_labels_path,
    ]
    for file_path in required_files:
        if not Path(file_path).exists():
            logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return 1

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        current_data = pd.read_csv(current_data_path)
        X_test = current_data
        y_test = pd.read_csv(test_labels_path).squeeze()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        feature_columns = X_test.columns.tolist()
        sensitive_attributes = [
            "grade",
            "emp_length",
        ]  # –ü—Ä–∏–º–µ—Ä —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤

        # –°–æ–∑–¥–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä
        monitor = ModelMonitor(
            model_path=model_path, reference_data_path=reference_data_path
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report = monitor.generate_monitoring_report(
            current_data=current_data,
            X_test=X_test,
            y_test=y_test,
            feature_columns=feature_columns,
            sensitive_attributes=sensitive_attributes,
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        monitor.save_monitoring_report(report, "monitoring/reports")

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–ª–µ—Ä—Ç—ã
        monitor.send_alerts(report)

        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
        print(f"\nüìä –û–¢–ß–ï–¢ –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê –ú–û–î–ï–õ–ò")
        print(f"–í—Ä–µ–º—è: {report['timestamp']}")
        print(f"–°—Ç–∞—Ç—É—Å: {report['overall_status']}")
        print(f"–ê–ª–µ—Ä—Ç–æ–≤: {len(report.get('alerts', []))}")

        if report.get("alerts"):
            print("\nüö® –ê–õ–ï–†–¢–´:")
            for alert in report["alerts"]:
                print(f"  [{alert['severity'].upper()}] {alert['message']}")

        return 0 if report["overall_status"] == "healthy" else 1

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ main: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
