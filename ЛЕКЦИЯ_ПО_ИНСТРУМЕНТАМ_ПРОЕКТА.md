# ЛЕКЦИЯ: Инструменты и команды проекта кредитного скоринга

## Содержание
1. [Обзор проекта](#обзор-проекта)
2. [Установка и настройка](#установка-и-настройка)
3. [Основные инструменты разработки](#основные-инструменты-разработки)
4. [Инструменты машинного обучения](#инструменты-машинного-обучения)
5. [Инструменты тестирования](#инструменты-тестирования)
6. [Инструменты качества кода](#инструменты-качества-кода)
7. [Инструменты контейнеризации](#инструменты-контейнеризации)
8. [Инструменты мониторинга](#инструменты-мониторинга)
9. [CI/CD и автоматизация](#cicd-и-автоматизация)
10. [Последовательность использования](#последовательность-использования)

---

## Обзор проекта

Проект представляет собой **полнофункциональную систему кредитного скоринга** с использованием современных инструментов разработки, машинного обучения и DevOps практик.

### Архитектура проекта:
- **Backend API**: FastAPI + Uvicorn
- **Frontend**: Streamlit + Gradio
- **ML Pipeline**: scikit-learn + XGBoost + LightGBM
- **Мониторинг**: Prometheus + Grafana + MLflow
- **Контейнеризация**: Docker + Docker Compose
- **CI/CD**: GitHub Actions
- **Тестирование**: pytest + coverage
- **Качество кода**: Black + isort + flake8 + mypy + bandit

---

## Установка и настройка

### 1. Системные требования
- **Python**: 3.8+ (рекомендуется 3.13)
- **Git**: для версионирования
- **Docker**: для контейнеризации (опционально)
- **Make**: для автоматизации команд (опционально)

### 2. Установка зависимостей

#### Вариант A: Через pip (рекомендуется)
```bash
# Клонирование репозитория
git clone <repository-url>
cd credit_scoring_project

# Создание виртуального окружения
python -m venv venv

# Активация виртуального окружения
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Установка зависимостей
pip install -r requirements.txt
```

#### Вариант B: Через Makefile
```bash
# Полная настройка проекта
make setup

# Или пошагово:
make install          # Установка зависимостей
make pre-commit-install # Установка pre-commit hooks
```

### 3. Настройка окружения
```bash
# Копирование конфигурации
cp env.example .env

# Редактирование настроек
# Отредактируйте .env файл с вашими настройками
```

---

## Основные инструменты разработки

### 1. Python 3.13
**Назначение**: Основной язык программирования проекта

**Установка**:
```bash
# Windows (через chocolatey)
choco install python

# Linux (Ubuntu/Debian)
sudo apt update
sudo apt install python3.13 python3.13-venv python3.13-pip

# Mac (через homebrew)
brew install python@3.13
```

**Проверка версии**:
```bash
python --version
# Должно показать: Python 3.13.x
```

### 2. Git
**Назначение**: Система контроля версий

**Установка**:
```bash
# Windows
# Скачать с https://git-scm.com/

# Linux
sudo apt install git

# Mac
brew install git
```

**Основные команды**:
```bash
git clone <repository-url>    # Клонирование репозитория
git status                    # Статус изменений
git add .                     # Добавление файлов в индекс
git commit -m "message"       # Создание коммита
git push origin main          # Отправка изменений
git pull origin main          # Получение изменений
```

### 3. Make
**Назначение**: Автоматизация команд и задач

**Установка**:
```bash
# Windows (через chocolatey)
choco install make

# Linux
sudo apt install make

# Mac (обычно уже установлен)
# Если нет: brew install make
```

**Основные команды проекта**:
```bash
make help                     # Показать все доступные команды
make install                  # Установить зависимости
make setup                    # Полная настройка проекта
make test-all                 # Запустить все тесты
make pipeline                 # Запустить ML пайплайн
make clean                    # Очистить временные файлы
```

---

## Инструменты машинного обучения

### 1. Pandas
**Назначение**: Обработка и анализ данных

**Установка**: `pip install pandas>=2.2.0`

**Основные команды**:
```python
import pandas as pd

# Загрузка данных
df = pd.read_csv('data/raw/accepted_2007_to_2018Q4.csv')

# Просмотр данных
df.head()
df.info()
df.describe()

# Обработка данных
df.dropna()  # Удаление пропусков
df.fillna(0)  # Заполнение пропусков
```

### 2. NumPy
**Назначение**: Численные вычисления

**Установка**: `pip install numpy>=1.26.0`

**Основные команды**:
```python
import numpy as np

# Создание массивов
arr = np.array([1, 2, 3, 4, 5])
zeros = np.zeros((3, 4))
ones = np.ones((2, 3))

# Математические операции
np.mean(arr)
np.std(arr)
np.median(arr)
```

### 3. Scikit-learn
**Назначение**: Машинное обучение

**Установка**: `pip install scikit-learn>=1.4.0`

**Основные команды**:
```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Разделение данных
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Обучение модели
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Предсказания
predictions = model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
```

### 4. XGBoost
**Назначение**: Градиентный бустинг

**Установка**: `pip install xgboost>=2.0.2`

**Основные команды**:
```python
import xgboost as xgb

# Создание и обучение модели
model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1
)
model.fit(X_train, y_train)
```

### 5. LightGBM
**Назначение**: Быстрый градиентный бустинг

**Установка**: `pip install lightgbm>=4.1.0`

**Основные команды**:
```python
import lightgbm as lgb

# Создание и обучение модели
model = lgb.LGBMClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1
)
model.fit(X_train, y_train)
```

### 6. MLflow
**Назначение**: Отслеживание экспериментов и управление моделями

**Установка**: `pip install mlflow>=2.8.1`

**Основные команды**:
```bash
# Запуск MLflow UI
mlflow ui --host 0.0.0.0 --port 5000

# Или через Makefile
make mlflow-ui
```

**Использование в коде**:
```python
import mlflow
import mlflow.sklearn

# Начало эксперимента
with mlflow.start_run():
    # Логирование параметров
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("max_depth", 6)
    
    # Обучение модели
    model = RandomForestClassifier(n_estimators=100, max_depth=6)
    model.fit(X_train, y_train)
    
    # Логирование метрик
    accuracy = model.score(X_test, y_test)
    mlflow.log_metric("accuracy", accuracy)
    
    # Сохранение модели
    mlflow.sklearn.log_model(model, "model")
```

### 7. Optuna
**Назначение**: Оптимизация гиперпараметров

**Установка**: `pip install optuna>=3.4.0`

**Основные команды**:
```python
import optuna

def objective(trial):
    # Определение гиперпараметров для оптимизации
    n_estimators = trial.suggest_int('n_estimators', 50, 200)
    max_depth = trial.suggest_int('max_depth', 3, 10)
    
    # Обучение модели
    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)
    model.fit(X_train, y_train)
    
    # Возврат метрики для оптимизации
    return model.score(X_test, y_test)

# Запуск оптимизации
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)
```

---

## Инструменты тестирования

### 1. Pytest
**Назначение**: Фреймворк для тестирования

**Установка**: `pip install pytest>=7.4.3`

**Конфигурация** (pytest.ini):
```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*
addopts = --strict-markers --verbose --cov=scripts --cov-report=html
markers =
    unit: Unit тесты
    integration: Интеграционные тесты
    e2e: End-to-end тесты
    slow: Медленные тесты
    fast: Быстрые тесты
```

**Основные команды**:
```bash
# Запуск всех тестов
pytest

# Запуск с покрытием
pytest --cov=scripts --cov-report=html

# Запуск конкретных тестов
pytest tests/unit/ -v
pytest tests/integration/ -v
pytest tests/e2e/ -v

# Запуск по маркерам
pytest -m "unit" -v
pytest -m "fast" -v
pytest -m "slow" -v

# Через Makefile
make test-all
make test-unit
make test-integration
make test-e2e
```

**Пример теста**:
```python
import pytest
from scripts.data_processing.preprocessing import preprocess_data

def test_preprocess_data():
    """Тест функции предобработки данных."""
    # Подготовка тестовых данных
    test_data = pd.DataFrame({
        'feature1': [1, 2, 3, None],
        'feature2': ['A', 'B', 'C', 'D']
    })
    
    # Выполнение функции
    result = preprocess_data(test_data)
    
    # Проверка результатов
    assert result is not None
    assert len(result) == 4
    assert result['feature1'].isna().sum() == 0
```

### 2. Coverage
**Назначение**: Измерение покрытия кода тестами

**Установка**: `pip install pytest-cov>=4.1.0`

**Основные команды**:
```bash
# Запуск с покрытием
pytest --cov=scripts --cov-report=html --cov-report=term-missing

# Генерация отчета
coverage html
coverage xml

# Через Makefile
make report-coverage
```

### 3. Pytest-xdist
**Назначение**: Параллельное выполнение тестов

**Установка**: `pip install pytest-xdist>=3.5.0`

**Основные команды**:
```bash
# Параллельное выполнение
pytest -n auto
pytest -n 4  # 4 процесса
```

---

## Инструменты качества кода

### 1. Black
**Назначение**: Автоматическое форматирование кода

**Установка**: `pip install black>=23.11.0`

**Основные команды**:
```bash
# Форматирование файлов
black scripts/
black tests/

# Проверка форматирования
black --check scripts/

# Форматирование с настройками
black --line-length 88 --target-version py311 scripts/

# Через Makefile
make format
make format-check
```

**Конфигурация** (.pre-commit-config.yaml):
```yaml
- repo: https://github.com/psf/black
  rev: 23.11.0
  hooks:
    - id: black
      args: [--line-length=88, --target-version=py311]
```

### 2. isort
**Назначение**: Сортировка импортов

**Установка**: `pip install isort>=5.12.0`

**Основные команды**:
```bash
# Сортировка импортов
isort scripts/
isort tests/

# Проверка сортировки
isort --check-only scripts/

# Сортировка с настройками
isort --profile black --line-length 88 scripts/

# Через Makefile
make format
```

### 3. Flake8
**Назначение**: Линтинг кода

**Установка**: `pip install flake8>=6.1.0`

**Основные команды**:
```bash
# Проверка кода
flake8 scripts/
flake8 tests/

# Проверка с настройками
flake8 --max-line-length=88 --extend-ignore=E203,W503 scripts/

# Через Makefile
make lint
```

### 4. MyPy
**Назначение**: Проверка типов

**Установка**: `pip install mypy>=1.7.1`

**Основные команды**:
```bash
# Проверка типов
mypy scripts/

# Проверка с игнорированием отсутствующих импортов
mypy --ignore-missing-imports scripts/

# Через Makefile
make lint
```

### 5. Bandit
**Назначение**: Проверка безопасности

**Установка**: `pip install bandit>=1.7.5`

**Основные команды**:
```bash
# Проверка безопасности
bandit -r scripts/

# Проверка с выводом в JSON
bandit -r scripts/ -f json -o bandit-report.json

# Через Makefile
make security-check
```

### 6. Pre-commit
**Назначение**: Автоматические проверки перед коммитом

**Установка**: `pip install pre-commit>=3.6.0`

**Основные команды**:
```bash
# Установка hooks
pre-commit install

# Запуск на всех файлах
pre-commit run --all-files

# Обновление hooks
pre-commit autoupdate

# Через Makefile
make pre-commit-install
make pre-commit-run
```

**Конфигурация** (.pre-commit-config.yaml):
```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-json
      - id: debug-statements
```

---

## Инструменты контейнеризации

### 1. Docker
**Назначение**: Контейнеризация приложений

**Установка**:
```bash
# Windows
# Скачать Docker Desktop с https://www.docker.com/

# Linux (Ubuntu/Debian)
sudo apt update
sudo apt install docker.io docker-compose
sudo systemctl start docker
sudo systemctl enable docker

# Mac
# Скачать Docker Desktop с https://www.docker.com/
```

**Основные команды**:
```bash
# Сборка образа
docker build -t credit-scoring .

# Запуск контейнера
docker run -p 8000:8000 credit-scoring

# Просмотр образов
docker images

# Просмотр контейнеров
docker ps
docker ps -a

# Остановка контейнера
docker stop <container_id>

# Удаление контейнера
docker rm <container_id>

# Удаление образа
docker rmi <image_id>

# Через Makefile
make docker-build
make docker-run
```

### 2. Docker Compose
**Назначение**: Оркестрация многоконтейнерных приложений

**Установка**: Обычно идет вместе с Docker

**Основные команды**:
```bash
# Запуск всех сервисов
docker-compose up -d

# Остановка всех сервисов
docker-compose down

# Просмотр логов
docker-compose logs

# Пересборка образов
docker-compose up --build

# Запуск конкретного сервиса
docker-compose up api
```

**Конфигурация** (docker-compose.yml):
```yaml
version: '3.8'
services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/credit_scoring_db
    depends_on:
      - db
      - redis
```

### 3. Dockerfile
**Назначение**: Инструкции для сборки Docker образа

**Основные команды в Dockerfile**:
```dockerfile
# Базовый образ
FROM python:3.13-slim

# Установка переменных окружения
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Установка системных зависимостей
RUN apt-get update && apt-get install -y gcc

# Установка Python зависимостей
COPY requirements.txt .
RUN pip install -r requirements.txt

# Копирование кода
COPY . .

# Создание пользователя
RUN groupadd -r appuser && useradd -r -g appuser appuser
USER appuser

# Открытие порта
EXPOSE 8000

# Команда запуска
CMD ["uvicorn", "api.simple_main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

## Инструменты мониторинга

### 1. Prometheus
**Назначение**: Сбор метрик

**Установка**: Через Docker Compose

**Основные команды**:
```bash
# Запуск через Docker Compose
docker-compose up prometheus

# Доступ к веб-интерфейсу
# http://localhost:9090
```

**Конфигурация** (monitoring/prometheus.yml):
```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'credit-scoring-api'
    static_configs:
      - targets: ['api:8000']
```

### 2. Grafana
**Назначение**: Визуализация метрик

**Установка**: Через Docker Compose

**Основные команды**:
```bash
# Запуск через Docker Compose
docker-compose up grafana

# Доступ к веб-интерфейсу
# http://localhost:3000
# Логин: admin, Пароль: admin
```

### 3. MLflow
**Назначение**: Отслеживание ML экспериментов

**Установка**: `pip install mlflow>=2.8.1`

**Основные команды**:
```bash
# Запуск MLflow UI
mlflow ui --host 0.0.0.0 --port 5000

# Или через Makefile
make mlflow-ui

# Доступ к веб-интерфейсу
# http://localhost:5000
```

### 4. Sentry
**Назначение**: Отслеживание ошибок

**Установка**: `pip install sentry-sdk[fastapi]>=1.38.0`

**Использование в коде**:
```python
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration

# Инициализация Sentry
sentry_sdk.init(
    dsn="YOUR_SENTRY_DSN",
    integrations=[FastApiIntegration()],
    traces_sample_rate=1.0,
)
```

---

## CI/CD и автоматизация

### 1. GitHub Actions
**Назначение**: Автоматизация CI/CD пайплайна

**Конфигурация** (.github/workflows/ci-cd.yml):
```yaml
name: Credit Scoring CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  code-quality:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.13'
    - name: Install dependencies
      run: pip install -r requirements.txt
    - name: Code formatting check
      run: black --check .
    - name: Linting
      run: flake8 .
```

**Основные этапы пайплайна**:
1. **Code Quality**: Проверка форматирования, линтинг
2. **Testing**: Запуск unit, integration, e2e тестов
3. **Data Validation**: Проверка качества данных
4. **Model Training**: Обучение моделей (при push в main)
5. **Deployment**: Развертывание в staging/production
6. **Model Monitoring**: Мониторинг качества модели

### 2. Makefile
**Назначение**: Автоматизация команд разработки

**Основные команды**:
```bash
# Установка и настройка
make install          # Установить зависимости
make setup            # Полная настройка проекта
make pre-commit-install # Установить pre-commit hooks

# Тестирование
make test-all         # Все тесты
make test-unit        # Unit тесты
make test-integration # Интеграционные тесты
make test-e2e         # E2E тесты

# Качество кода
make format           # Форматировать код
make lint             # Проверить линтерами
make quality-check    # Полная проверка качества

# ML пайплайн
make pipeline         # Полный пайплайн
make pipeline-eda     # Только EDA
make pipeline-training # Только обучение

# Docker
make docker-build     # Собрать Docker образ
make docker-run       # Запустить в Docker

# Очистка
make clean            # Очистить временные файлы
make clean-all        # Полная очистка
```

---

## Последовательность использования

### Этап 1: Первоначальная настройка

```bash
# 1. Клонирование репозитория
git clone <repository-url>
cd credit_scoring_project

# 2. Создание виртуального окружения
python -m venv venv

# 3. Активация виртуального окружения
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 4. Установка зависимостей
pip install -r requirements.txt

# 5. Настройка pre-commit hooks
python scripts/setup_pre_commit.py

# 6. Копирование конфигурации
cp env.example .env
# Отредактируйте .env файл
```

### Этап 2: Подготовка данных

```bash
# 1. Поместите файл данных в папку data/raw/
# Файл должен называться: accepted_2007_to_2018Q4.csv

# 2. Проверка наличия данных
ls data/raw/
```

### Этап 3: Запуск ML пайплайна

#### Вариант A: Полный пайплайн (рекомендуется)
```bash
# Запуск всех этапов последовательно
python scripts/run_pipeline.py

# Или через Makefile
make pipeline
```

#### Вариант B: Пошаговый запуск
```bash
# 1. Исследовательский анализ данных (EDA)
python scripts/data_processing/eda.py
# Или: make pipeline-eda

# 2. Предобработка данных
python scripts/data_processing/preprocessing.py
# Или: make pipeline-preprocessing

# 3. Обучение моделей
python scripts/model_training/train_models.py
# Или: make pipeline-training

# 4. Подбор гиперпараметров
python scripts/model_training/hyperparameter_tuning.py
# Или: make pipeline-tuning

# 5. Валидация моделей
python scripts/model_training/validation.py
# Или: make pipeline-validation
```

### Этап 4: Тестирование

```bash
# 1. Запуск всех тестов
pytest tests/ -v

# Или через Makefile
make test-all

# 2. Запуск конкретных типов тестов
make test-unit        # Unit тесты
make test-integration # Интеграционные тесты
make test-e2e         # E2E тесты

# 3. Запуск с покрытием кода
pytest --cov=scripts --cov-report=html
```

### Этап 5: Проверка качества кода

```bash
# 1. Форматирование кода
black scripts/ tests/
isort scripts/ tests/

# Или через Makefile
make format

# 2. Проверка линтерами
flake8 scripts/ tests/
mypy scripts/
bandit -r scripts/

# Или через Makefile
make lint

# 3. Полная проверка качества
make quality-check
```

### Этап 6: Запуск приложения

#### Вариант A: Локальный запуск
```bash
# 1. Запуск API
uvicorn api.simple_main:app --host 0.0.0.0 --port 8000 --reload

# Или через Makefile
make start-api

# 2. Запуск frontend (в другом терминале)
streamlit run frontend/app.py --server.port 8501

# Или через Makefile
make start-frontend

# 3. Запуск всех сервисов
make start-all
```

#### Вариант B: Docker
```bash
# 1. Сборка Docker образа
docker build -t credit-scoring .

# Или через Makefile
make docker-build

# 2. Запуск через Docker Compose
docker-compose up -d

# 3. Проверка статуса
docker-compose ps
```

### Этап 7: Мониторинг

```bash
# 1. Запуск MLflow UI
mlflow ui --host 0.0.0.0 --port 5000

# Или через Makefile
make mlflow-ui

# 2. Запуск мониторинга модели
python scripts/monitoring/model_monitoring.py

# Или через Makefile
make monitoring-model

# 3. Запуск мониторинга данных
python scripts/monitoring/data_quality_monitor.py

# Или через Makefile
make monitoring-data
```

### Этап 8: Разработка

```bash
# 1. Создание новой ветки
git checkout -b feature/new-feature

# 2. Разработка с автоматическими проверками
# Pre-commit hooks будут запускаться автоматически при коммите

# 3. Ручной запуск проверок
make dev-test    # Быстрое тестирование
make dev-lint    # Линтинг

# 4. Коммит изменений
git add .
git commit -m "Add new feature"
git push origin feature/new-feature

# 5. Создание Pull Request
# Через веб-интерфейс GitHub
```

### Этап 9: Очистка

```bash
# 1. Очистка временных файлов
make clean

# 2. Очистка данных
make clean-data

# 3. Полная очистка
make clean-all

# 4. Очистка Docker
make docker-clean
```

---

## Полезные команды для отладки

### Отладка пайплайна
```bash
# Запуск с отладкой
python -m pdb scripts/run_pipeline.py

# Или через Makefile
make debug-pipeline
```

### Отладка тестов
```bash
# Запуск тестов с отладкой
pytest tests/ -v --pdb

# Или через Makefile
make debug-test
```

### Профилирование
```bash
# Профилирование пайплайна
python -m cProfile -o pipeline.prof scripts/run_pipeline.py

# Или через Makefile
make profile-pipeline
```

### Статистика проекта
```bash
# Статистика строк кода
make stats-lines

# Статистика файлов
make stats-files
```

---

## Заключение

Данный проект представляет собой комплексную систему кредитного скоринга с использованием современных инструментов разработки, машинного обучения и DevOps практик. Все инструменты интегрированы и работают совместно для обеспечения высокого качества кода, надежности системы и удобства разработки.

**Ключевые преимущества**:
- Автоматизация всех этапов разработки
- Высокое качество кода благодаря множественным проверкам
- Полная воспроизводимость через контейнеризацию
- Комплексный мониторинг и отслеживание экспериментов
- CI/CD пайплайн для автоматического тестирования и развертывания

**Рекомендации по использованию**:
1. Всегда используйте виртуальное окружение
2. Запускайте pre-commit hooks перед каждым коммитом
3. Тестируйте код перед отправкой в репозиторий
4. Используйте Makefile для стандартизации команд
5. Следите за метриками качества модели через MLflow
6. Регулярно обновляйте зависимости
